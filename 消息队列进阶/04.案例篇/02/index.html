<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-two/umi.css" />
    <script>
      window.routerBase = "/blog-two";
    </script>
    <script>
      //! umi version: 3.5.17
    </script>
    <script>
      !(function () {
        var e = localStorage.getItem("dumi:prefers-color"),
          t = window.matchMedia("(prefers-color-scheme: dark)").matches,
          r = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === r[2] ? (t ? r[1] : r[0]) : r.indexOf(e) > -1 ? e : r[0]
        );
      })();
    </script>
    <title>30 | 流计算与消息（二）：在流计算中使用Kafka链接计算任务</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/消息队列进阶/04.案例篇/02" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-two/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-two/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-two/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-two/零基础学python">零基础学python</a></li><li><a href="/blog-two/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-two/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-two/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-two/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-two/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li></ul></span><span>架构师<ul><li><a href="/blog-two/持续交付36讲">持续交付36讲</a></li><li><a href="/blog-two/容器实战高手课">容器实战高手课</a></li><li><a href="/blog-two/ddd实战课">ddd实战课</a></li><li><a href="/blog-two/设计模式之美">设计模式之美</a></li><li><a href="/blog-two/devops实战笔记">devops实战笔记</a></li><li><a href="/blog-two/架构实战案例解析">架构实战案例解析</a></li><li><a href="/blog-two/许式伟的架构课">许式伟的架构课</a></li><li><a href="/blog-two/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-two/深入剖析kubernetes">深入剖析kubernetes</a></li><li><a href="/blog-two/说透中台">说透中台</a></li><li><a aria-current="page" class="active" href="/blog-two/消息队列进阶">消息队列进阶</a></li><li><a href="/blog-two/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-two/openresty从入门到实战">openresty从入门到实战</a></li><li><a href="/blog-two/赵成的运维体系管理课">赵成的运维体系管理课</a></li><li><a href="/blog-two/性能测试实战30讲">性能测试实战30讲</a></li><li><a href="/blog-two/安全攻防技能30讲">安全攻防技能30讲</a></li><li><a href="/blog-two/从0开始学架构">从0开始学架构</a></li><li><a href="/blog-two/vim实用技巧必知必会">vim实用技巧必知必会</a></li><li><a href="/blog-two/如何落地业务建模">如何落地业务建模</a></li><li><a href="/blog-two/技术与商业案例解读">技术与商业案例解读</a></li><li><a href="/blog-two/说透数字化转型">说透数字化转型</a></li><li><a href="/blog-two/遗留系统现代化实战">遗留系统现代化实战</a></li></ul></span><span>管理<ul><li><a href="/blog-two/技术管理实战36讲">技术管理实战36讲</a></li><li><a href="/blog-two/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-two/项目管理实战课">项目管理实战课</a></li><li><a href="/blog-two/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-two/技术领导力实战笔记">技术领导力实战笔记</a></li><li><a href="/blog-two/朱赟的技术管理">朱赟的技术管理</a></li></ul></span><span>工作生活<ul><li><a href="/blog-two/10x程序员工作法">10x程序员工作法</a></li><li><a href="/blog-two/python自动化办公实战课">python自动化办公实战课</a></li><li><a href="/blog-two/人人都用得上的写作课">人人都用得上的写作课</a></li><li><a href="/blog-two/体验设计案例课">体验设计案例课</a></li><li><a href="/blog-two/用户体验设计实战课">用户体验设计实战课</a></li><li><a href="/blog-two/程序员的个人财富课">程序员的个人财富课</a></li><li><a href="/blog-two/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-two/职场求生攻略">职场求生攻略</a></li><li><a href="/blog-two/讲好故事">讲好故事</a></li><li><a href="/blog-two/跟着高手学复盘">跟着高手学复盘</a></li></ul></span><span>杂谈</span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-two/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-two/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-two/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-two/零基础学python">零基础学python</a></li><li><a href="/blog-two/redis核心技术与实战">redis核心技术与实战</a></li><li><a href="/blog-two/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-two/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-two/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-two/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li></ul></li><li>架构师<ul><li><a href="/blog-two/持续交付36讲">持续交付36讲</a></li><li><a href="/blog-two/容器实战高手课">容器实战高手课</a></li><li><a href="/blog-two/ddd实战课">ddd实战课</a></li><li><a href="/blog-two/设计模式之美">设计模式之美</a></li><li><a href="/blog-two/devops实战笔记">devops实战笔记</a></li><li><a href="/blog-two/架构实战案例解析">架构实战案例解析</a></li><li><a href="/blog-two/许式伟的架构课">许式伟的架构课</a></li><li><a href="/blog-two/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-two/深入剖析kubernetes">深入剖析kubernetes</a></li><li><a href="/blog-two/说透中台">说透中台</a></li><li><a aria-current="page" class="active" href="/blog-two/消息队列进阶">消息队列进阶</a></li><li><a href="/blog-two/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-two/openresty从入门到实战">openresty从入门到实战</a></li><li><a href="/blog-two/赵成的运维体系管理课">赵成的运维体系管理课</a></li><li><a href="/blog-two/性能测试实战30讲">性能测试实战30讲</a></li><li><a href="/blog-two/安全攻防技能30讲">安全攻防技能30讲</a></li><li><a href="/blog-two/从0开始学架构">从0开始学架构</a></li><li><a href="/blog-two/vim实用技巧必知必会">vim实用技巧必知必会</a></li><li><a href="/blog-two/如何落地业务建模">如何落地业务建模</a></li><li><a href="/blog-two/技术与商业案例解读">技术与商业案例解读</a></li><li><a href="/blog-two/说透数字化转型">说透数字化转型</a></li><li><a href="/blog-two/遗留系统现代化实战">遗留系统现代化实战</a></li></ul></li><li>管理<ul><li><a href="/blog-two/技术管理实战36讲">技术管理实战36讲</a></li><li><a href="/blog-two/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-two/项目管理实战课">项目管理实战课</a></li><li><a href="/blog-two/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-two/技术领导力实战笔记">技术领导力实战笔记</a></li><li><a href="/blog-two/朱赟的技术管理">朱赟的技术管理</a></li></ul></li><li>工作生活<ul><li><a href="/blog-two/10x程序员工作法">10x程序员工作法</a></li><li><a href="/blog-two/python自动化办公实战课">python自动化办公实战课</a></li><li><a href="/blog-two/人人都用得上的写作课">人人都用得上的写作课</a></li><li><a href="/blog-two/体验设计案例课">体验设计案例课</a></li><li><a href="/blog-two/用户体验设计实战课">用户体验设计实战课</a></li><li><a href="/blog-two/程序员的个人财富课">程序员的个人财富课</a></li><li><a href="/blog-two/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-two/职场求生攻略">职场求生攻略</a></li><li><a href="/blog-two/讲好故事">讲好故事</a></li><li><a href="/blog-two/跟着高手学复盘">跟着高手学复盘</a></li></ul></li><li>杂谈</li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-two/消息队列进阶">消息队列进阶</a></li><li><a href="/blog-two/消息队列进阶/01.课前必读">01.课前必读</a><ul><li><a href="/blog-two/消息队列进阶/01.课前必读/01"><span>开篇词 | 优秀的程序员，你的技术栈中不能只有“增删改查”</span></a></li><li><a href="/blog-two/消息队列进阶/01.课前必读/02"><span>预习 | 怎样更好地学习这门课？</span></a></li></ul></li><li><a href="/blog-two/消息队列进阶/02.基础篇">02.基础篇</a><ul><li><a href="/blog-two/消息队列进阶/02.基础篇/01"><span>01 | 为什么需要消息队列？</span></a></li><li><a href="/blog-two/消息队列进阶/02.基础篇/02"><span>02 | 该如何选择消息队列？</span></a></li><li><a href="/blog-two/消息队列进阶/02.基础篇/03"><span>03 | 消息模型：主题和队列有什么区别？</span></a></li><li><a href="/blog-two/消息队列进阶/02.基础篇/04"><span>04 | 如何利用事务消息实现分布式事务？</span></a></li><li><a href="/blog-two/消息队列进阶/02.基础篇/05"><span>05 | 如何确保消息不会丢失?</span></a></li><li><a href="/blog-two/消息队列进阶/02.基础篇/06"><span>06 | 如何处理消费过程中的重复消息？</span></a></li><li><a href="/blog-two/消息队列进阶/02.基础篇/07"><span>07 | 消息积压了该如何处理？</span></a></li><li><a href="/blog-two/消息队列进阶/02.基础篇/08"><span>08 | 答疑解惑（一） : 网关如何接收服务端的秒杀结果？</span></a></li></ul></li><li><a href="/blog-two/消息队列进阶/03.进阶篇">03.进阶篇</a><ul><li><a href="/blog-two/消息队列进阶/03.进阶篇/01"><span>09 | 学习开源代码该如何入手？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/02"><span>10 | 如何使用异步设计提升系统性能？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/03"><span>11 | 如何实现高性能的异步网络传输？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/04"><span>12 | 序列化与反序列化：如何通过网络传输结构化的数据？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/05"><span>13 | 传输协议：应用程序之间对话的语言</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/06"><span>14 | 内存管理：如何避免内存溢出和频繁的垃圾回收？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/07"><span>加餐 | JMQ的Broker是如何异步处理消息的？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/08"><span>15 | Kafka如何实现高性能IO？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/09"><span>16 | 缓存策略：如何使用缓存来减少磁盘IO？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/10"><span>17 | 如何正确使用锁保护共享数据，协调异步线程？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/11"><span>18 | 如何用硬件同步原语（CAS）替代锁？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/12"><span>19 | 数据压缩：时间换空间的游戏</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/13"><span>20 | RocketMQ Producer源码分析：消息生产的实现过程</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/14"><span>21 | Kafka Consumer源码分析：消息消费的实现过程</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/15"><span>22 | Kafka和RocketMQ的消息复制实现的差异点在哪？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/16"><span>23 | RocketMQ客户端如何在集群中找到正确的节点？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/17"><span>24 | Kafka的协调服务ZooKeeper：实现分布式系统的“瑞士军刀”</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/18"><span>25 | RocketMQ与Kafka中如何实现事务？</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/19"><span>26 | MQTT协议：如何支持海量的在线IoT设备?</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/20"><span>27 | Pulsar的存储计算分离设计：全新的消息队列设计思路</span></a></li><li><a href="/blog-two/消息队列进阶/03.进阶篇/21"><span>28 | 答疑解惑（二）：我的100元哪儿去了？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-two/消息队列进阶/04.案例篇">04.案例篇</a><ul><li><a href="/blog-two/消息队列进阶/04.案例篇/01"><span>29 | 流计算与消息（一）：通过Flink理解流计算的原理</span></a></li><li><a aria-current="page" class="active" href="/blog-two/消息队列进阶/04.案例篇/02"><span>30 | 流计算与消息（二）：在流计算中使用Kafka链接计算任务</span></a></li><li><a href="/blog-two/消息队列进阶/04.案例篇/03"><span>31 | 动手实现一个简单的RPC框架（一）：原理和程序的结构</span></a></li><li><a href="/blog-two/消息队列进阶/04.案例篇/04"><span>32 | 动手实现一个简单的RPC框架（二）：通信与序列化</span></a></li><li><a href="/blog-two/消息队列进阶/04.案例篇/05"><span>33 | 动手实现一个简单的RPC框架（三）：客户端</span></a></li><li><a href="/blog-two/消息队列进阶/04.案例篇/06"><span>34 | 动手实现一个简单的RPC框架（四）：服务端</span></a></li><li><a href="/blog-two/消息队列进阶/04.案例篇/07"><span>35 | 答疑解惑（三）：主流消息队列都是如何存储消息的？</span></a></li></ul></li><li><a href="/blog-two/消息队列进阶/05.测试篇">05.测试篇</a><ul><li><a href="/blog-two/消息队列进阶/05.测试篇/01"><span>期中测试丨10个消息队列热点问题自测</span></a></li><li><a href="/blog-two/消息队列进阶/05.测试篇/02"><span>期末测试 | 消息队列100分试卷等你来挑战！</span></a></li></ul></li><li><a href="/blog-two/消息队列进阶/06.结束语">06.结束语</a><ul><li><a href="/blog-two/消息队列进阶/06.结束语/01"><span>结束语 | 程序员如何构建知识体系？</span></a></li><li><a href="/blog-two/消息队列进阶/06.结束语/02"><span>第二季回归丨这次我们一起实战后端存储</span></a></li></ul></li><li><a href="/blog-two/消息队列进阶/summary">消息队列进阶</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="Flink是如何保证Exactly Once语义的？" data-depth="2"><a href="/blog-two/消息队列进阶/04.案例篇/02#flink是如何保证exactly-once语义的"><span>Flink是如何保证Exactly Once语义的？</span></a></li><li title="Kafka如何配合Flink实现端到端Exactly Once？" data-depth="2"><a href="/blog-two/消息队列进阶/04.案例篇/02#kafka如何配合flink实现端到端exactly-once"><span>Kafka如何配合Flink实现端到端Exactly Once？</span></a></li><li title="Exactly Once版本的Web请求的统计" data-depth="2"><a href="/blog-two/消息队列进阶/04.案例篇/02#exactly-once版本的web请求的统计"><span>Exactly Once版本的Web请求的统计</span></a></li><li title="小结" data-depth="2"><a href="/blog-two/消息队列进阶/04.案例篇/02#小结"><span>小结</span></a></li><li title="思考题" data-depth="2"><a href="/blog-two/消息队列进阶/04.案例篇/02#思考题"><span>思考题</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="30--流计算与消息二在流计算中使用kafka链接计算任务"><a aria-hidden="true" tabindex="-1" href="/blog-two/消息队列进阶/04.案例篇/02#30--流计算与消息二在流计算中使用kafka链接计算任务"><span class="icon icon-link"></span></a>30 | 流计算与消息（二）：在流计算中使用Kafka链接计算任务</h1><p>你好，我是李玥。</p><p>上节课我们一起实现了一个流计算的例子，并通过这个例子学习了流计算的实现原理。我们知道，流计算框架本身是个分布式系统，一般由多个节点组成一个集群。我们的计算任务在计算集群中运行的时候，会被拆分成多个子任务，这些子任务也是分布在集群的多个计算节点上的。</p><p>大部分流计算平台都会采用存储计算分离的设计，将计算任务的状态保存在HDFS等分布式存储系统中。每个子任务将状态分离出去之后，就变成了无状态的节点，如果某一个计算节点发生宕机，使用集群中任意一个节点都可以替代故障节点。</p><p>但是，对流计算来说，这里面还有一个问题没解决，就是在集群中流动的数据并没有被持久化，所以它们就有可能由于节点故障而丢失，怎么解决这个问题呢？办法也比较简单粗暴，就是直接重启整个计算任务，并且从数据源头向前回溯一些数据。计算任务重启之后，会重新分配计算节点，顺便就完成了故障迁移。</p><p>回溯数据源，可以保证数据不丢失，这和消息队列中，通过重发未成功的消息来保证数据不丢的方法是类似的。所以，它们面临同样的问题：可能会出现重复的消息。消息队列可以通过在消费端做幂等来克服这个问题，但是对于流计算任务来说，这个问题就很棘手了。</p><p>对于接收计算结果的下游系统，它可能会收到重复的计算结果，这还不是最糟糕的。像一些统计类的计算任务，就会有比较大的影响，比如上节课中统计访问次数的例子，本来这个IP地址在统计周期内被访问了5次，产生了5条访问日志，正确的结果应该是5次。如果日志被重复统计，那结果就会多于5次，重复的数据导致统计结果出现了错误。怎么解决这个问题呢？</p><p>我们之前提到过，Kafka支持Exactly Once语义，它的这个特性就是为了解决这个问题而生的。这节课，我们就来通过一个例子学习一下，如何使用Kafka配合Flink，解决数据重复的问题，实现端到端的Exactly Once语义。</p><h2 id="flink是如何保证exactly-once语义的"><a aria-hidden="true" tabindex="-1" href="/blog-two/消息队列进阶/04.案例篇/02#flink是如何保证exactly-once语义的"><span class="icon icon-link"></span></a>Flink是如何保证Exactly Once语义的？</h2><p>我们所说的端到端Exactly Once，这里面的“端到端”指的是，数据从Kafka的A主题消费，发送给Flink的计算集群进行计算，计算结果再发给Kafka的B主题。在这整个过程中，无论是Kafka集群的节点还是Flink集群的节点发生故障，都不会影响计算结果，每条消息只会被计算一次，不能多也不能少。</p><p>在理解端到端Exactly Once的实现原理之前，我们需要先了解一下，Flink集群本身是如何保证Exactly Once语义的。为什么Flink也需要保证Exactly Once呢？Flink集群本身也是一个分布式系统，它首先需要保证数据在Flink集群内部只被计算一次，只有在这个基础上，才谈得到端到端的Exactly Once。</p><p>Flink通过CheckPoint机制来定期保存计算任务的快照，这个快照中主要包含两个重要的数据：</p><ol><li>整个计算任务的状态。这个状态主要是计算任务中，每个子任务在计算过程中需要保存的临时状态数据。比如，上节课例子中汇总了一半的数据。</li><li>数据源的位置信息。这个信息记录了在数据源的这个流中已经计算了哪些数据。如果数据源是Kafka的主题，这个位置信息就是Kafka主题中的消费位置。</li></ol><p>有了CheckPoint，当计算任务失败重启的时候，可以从最近的一个CheckPoint恢复计算任务。具体的做法是，每个子任务先从CheckPoint中读取并恢复自己的状态，然后整个计算任务从CheckPoint中记录的数据源位置开始消费数据，只要这个恢复位置和CheckPoint中每个子任务的状态是完全对应的，或者说，每个子任务的状态恰好是：“刚刚处理完恢复位置之前的那条数据，还没有开始处理恢复位置对应的这条数据”，这个时刻保存的状态，就可以做到严丝合缝地恢复计算任务，每一条数据既不会丢失也不会重复。</p><p>因为每个子任务分布在不同的节点上，并且数据是一直在子任务中流动的，所以确保CheckPoint中记录的恢复位置和每个子任务的状态完全对应并不是一件容易的事儿，Flink是怎么实现的呢？</p><p>Flink通过在数据流中插入一个Barrier（屏障）来确保CheckPoint中的位置和状态完全对应。下面这张图来自<a target="_blank" rel="noopener noreferrer" href="https://ci.apache.org/projects/flink/flink-docs-stable/internals/stream_checkpointing.html">Flink官网的说明文档<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p><p><img src="https://static001.geekbang.org/resource/image/0c/fa/0c301d798341dc53515611c31e9031fa.png" alt=""/></p><p>你可以把Barrier理解为一条特殊的数据。Barrier由Flink生成，并在数据进入计算集群时被插入到数据流中。这样，无限的数据流就被很多的Barrier分隔成很多段。Barrier在流经每个计算节点的时候，就会触发这个节点在CheckPoint中保存本节点的状态，如果这个节点是数据源节点，还会保存数据源的位置。</p><p>当一个Barrier流过所有计算节点，流出计算集群后，一个CheckPoint也就保存完成了。由于每个节点都是在Barrier流过的时候保存的状态，这时的状态恰好就是Barrier所在位置（也就是CheckPoint数据源位置）对应的状态，这样就完美解决了状态与恢复位置对应的问题。</p><p>Flink通过CheckPoint机制实现了集群内计算任务的Exactly Once语义，但是仍然实现不了在输入和输出两端数据不丢不重。比如，Flink在把一条计算结果发给Kafka并收到来自Kafka的“发送成功”响应之后，才会继续处理下一条数据。如果这个时候重启计算任务，Flink集群内的数据都可以完美地恢复到上一个CheckPoint，但是已经发给Kafka的消息却没办法撤回，还是会出现数据重复的问题。</p><p>所以，我们需要配合Kafka的Exactly Once机制，才能实现端到端的Exactly Once。</p><h2 id="kafka如何配合flink实现端到端exactly-once"><a aria-hidden="true" tabindex="-1" href="/blog-two/消息队列进阶/04.案例篇/02#kafka如何配合flink实现端到端exactly-once"><span class="icon icon-link"></span></a>Kafka如何配合Flink实现端到端Exactly Once？</h2><p>Kafka的Exactly Once语义是通过它的事务和生产幂等两个特性来共同实现的。其中Kafka事务的实现原理，我们在《<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/138724">25 | RocketMQ与Kafka中如何实现事务？<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>》这节课中讲过。它可以保证一个事务内的所有消息，要么都成功投递，要么都不投递。</p><p>生产幂等这个特性可以保证，在生产者给Kafka Broker发送消息这个过程中，消息不会重复发送。这个实现原理和我们在《<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/111488">05 | 如何确保消息不会丢失？<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>》这节课中介绍的“检测消息丢失”的方法是类似的，都是通过连续递增的序号进行检测。Kafka的生产者给每个消息增加都附加一个连续递增的序号，Broker端会检测这个序号的连续性，如果序号重复了，Broker会拒绝这个重复消息。</p><p>Kafka的这两个机制，配合Flink就可以来实现端到端的Exactly Once了。简单地说就是，每个Flink的CheckPoint对应一个Kafka事务。Flink在创建一个CheckPoint的时候，同时开启一个Kafka的事务，完成CheckPoint同时提交Kafka的事务。当计算任务重启的时候，在Flink中计算任务会恢复到上一个CheckPoint，这个CheckPoint正好对应Kafka上一个成功提交的事务。未完成的CheckPoint和未提交的事务中的消息都会被丢弃，这样就实现了端到端的Exactly Once。</p><p>但是，怎么才能保证“完成CheckPoint同时提交Kafka的事务”呢？或者说，如何来保证“完成CheckPoint”和“提交Kafka事务”这两个操作，要么都成功，要么都失败呢？这不就是一个典型的分布式事务问题嘛！</p><p>所以，Flink基于两阶段提交这个常用的分布式事务算法，实现了一分布式事务的控制器来解决这个问题。如果你对具体的实现原理感兴趣，可以看一下Flink官网文档中的<a target="_blank" rel="noopener noreferrer" href="https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html">这篇文章<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p><h2 id="exactly-once版本的web请求的统计"><a aria-hidden="true" tabindex="-1" href="/blog-two/消息队列进阶/04.案例篇/02#exactly-once版本的web请求的统计"><span class="icon icon-link"></span></a>Exactly Once版本的Web请求的统计</h2><p>下面进入实战环节，我们来把上节课的“统计Web请求的次数”的Flink Job改造一下，让这个Job具备Exactly Once特性。这个实时统计任务接收NGINX的access.log，每5秒钟按照IP地址统计Web请求的次数。假设我们已经有一个实时发送access.log的日志服务来发送日志，日志的内容只包含访问时间和IP地址，这个日志服务就是我们流计算任务的数据源。</p><p>改造之后，我们需要把数据的来源替换成Kafka的ip_count_source主题，计算结果也要保存到Kafka的主题ip_count_sink中。</p><p>整个系统的数据流向就变成下图这样：</p><p><img src="https://static001.geekbang.org/resource/image/b6/6d/b62a67148c0600a1814f763a70b2056d.jpg" alt=""/></p><p>日志服务将日志数据发送到Kafka的主题ip_count_source，计算任务消费这个主题的数据作为数据源，计算结果会被写入到Kafka的主题ip_count_sink中。</p><p>Flink提供了Kafka Connector模块，可以作为数据源从Kafka中消费数据，也可以作为Kafka的Producer，将计算结果发送给Kafka，并且，这个Kafka Connector已经实现了Exactly Once语义，我们在使用的时候只要做适当的配置就可以了。</p><p>这次我们用Java语言来实现这个任务，改造后的计算任务代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">public class ExactlyOnceIpCount {</span></div><div class="token-line"><span class="token plain">        public static void main(String[] args) throws Exception {</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // 设置输入和输出</span></div><div class="token-line"><span class="token plain">            FlinkKafkaConsumer011&lt;IpAndCount&gt; sourceConsumer = setupSource();</span></div><div class="token-line"><span class="token plain">            FlinkKafkaProducer011&lt;String&gt; sinkProducer = setupSink();</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // 设置运行时环境</span></div><div class="token-line"><span class="token plain">            final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span></div><div class="token-line"><span class="token plain">            env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime); // 按照EventTime来统计</span></div><div class="token-line"><span class="token plain">            env.enableCheckpointing(5000); // 每5秒保存一次CheckPoint</span></div><div class="token-line"><span class="token plain">            // 设置CheckPoint</span></div><div class="token-line"><span class="token plain">            CheckpointConfig config = env.getCheckpointConfig();</span></div><div class="token-line"><span class="token plain">            config.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE); // 设置CheckPoint模式为EXACTLY_ONCE</span></div><div class="token-line"><span class="token plain">            config.enableExternalizedCheckpoints(</span></div><div class="token-line"><span class="token plain">                    CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION); // 取消任务时保留CheckPoint</span></div><div class="token-line"><span class="token plain">            config.setPreferCheckpointForRecovery(true); // 启动时从CheckPoint恢复任务</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // 设置CheckPoint的StateBackend，在这里CheckPoint保存在本地临时目录中。</span></div><div class="token-line"><span class="token plain">            // 只适合单节点做实验，在生产环境应该使用分布式文件系统，例如HDFS。</span></div><div class="token-line"><span class="token plain">            File tmpDirFile = new File(System.getProperty(&quot;java.io.tmpdir&quot;));</span></div><div class="token-line"><span class="token plain">            env.setStateBackend((StateBackend) new FsStateBackend(tmpDirFile.toURI().toURL().toString()));</span></div><div class="token-line"><span class="token plain">            // 设置故障恢复策略：任务失败的时候自动每隔10秒重启，一共尝试重启3次</span></div><div class="token-line"><span class="token plain">            env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span></div><div class="token-line"><span class="token plain">                    3, // number of restart attempts</span></div><div class="token-line"><span class="token plain">                    10000 // delay</span></div><div class="token-line"><span class="token plain">            ));</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // 定义输入：从Kafka中获取数据</span></div><div class="token-line"><span class="token plain">            DataStream&lt;IpAndCount&gt; input = env</span></div><div class="token-line"><span class="token plain">                    .addSource(sourceConsumer);</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // 计算：每5秒钟按照ip对count求和</span></div><div class="token-line"><span class="token plain">            DataStream&lt;IpAndCount&gt; output =</span></div><div class="token-line"><span class="token plain">                    input</span></div><div class="token-line"><span class="token plain">                    .keyBy(IpAndCount::getIp) // 按照ip地址统计</span></div><div class="token-line"><span class="token plain">                    .window(TumblingEventTimeWindows.of(Time.seconds(5))) // 每5秒钟统计一次</span></div><div class="token-line"><span class="token plain">                    .allowedLateness(Time.seconds(5))</span></div><div class="token-line"><span class="token plain">                    .sum(&quot;count&quot;); // 对count字段求和</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // 输出到kafka topic</span></div><div class="token-line"><span class="token plain">            output.map(IpAndCount::toString).addSink(sinkProducer);</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">            // execute program</span></div><div class="token-line"><span class="token plain">            env.execute(&quot;Exactly-once IpCount&quot;);</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>这段代码和上节课中原始版本的代码整体架构是差不多的，同样是：定义数据源、定义计算逻辑和定义输入这三大步骤。下面主要来说不同之处，这些不同的地方也就是如何配置Exactly Once特性的关键点。</p><p>首先，我们需要开启并配置好CheckPoint。在这段代码中，我们开启了CheckPoint，设置每5秒钟创建一个CheckPoint。然后，还需要定义保存CheckPoint的StateBackend，也就是告诉Flink把CheckPoint保存在哪儿。在生产环境中，CheckPoint应该保存到HDFS这样的分布式文件系统中。我们这个例子中，为了方便运行调试，直接把CheckPoint保存到本地的临时目录中。之后，我们还需要将Job配置成自动重启，这样当节点发生故障时，Flink会自动重启Job并从最近一次CheckPoint开始恢复。</p><p>我们在定义输出创建FlinkKafkaProducer的时候，需要指定Exactly Once语义，这样Flink才会开启Kafka的事务，代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">private static FlinkKafkaProducer011&lt;String&gt; setupSink() {</span></div><div class="token-line"><span class="token plain">        // 设置Kafka Producer属性</span></div><div class="token-line"><span class="token plain">        Properties producerProperties = new Properties();</span></div><div class="token-line"><span class="token plain">        producerProperties.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span></div><div class="token-line"><span class="token plain">        // 事务超时时间设置为1分钟</span></div><div class="token-line"><span class="token plain">        producerProperties.put(&quot;transaction.timeout.ms&quot;, &quot;60000&quot;);</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">        // 创建 FlinkKafkaProducer，指定语义为EXACTLY_ONCE</span></div><div class="token-line"><span class="token plain">        return new FlinkKafkaProducer011&lt;&gt;(</span></div><div class="token-line"><span class="token plain">                &quot;ip_count_sink&quot;,</span></div><div class="token-line"><span class="token plain">                new KeyedSerializationSchemaWrapper&lt;&gt;(new SimpleStringSchema()),</span></div><div class="token-line"><span class="token plain">                producerProperties,</span></div><div class="token-line"><span class="token plain">                FlinkKafkaProducer011.Semantic.EXACTLY_ONCE);</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>最后一点需要注意的，在从Kafka主题ip_count_sink中消费计算结果的时候，需要配置Consumer属性：isolation.level=read_committed，也就是只消费已提交事务的消息。因为默认情况下，Kafka的Consumer是可以消费到未提交事务的消息的。</p><p>这个例子的完整代码我放到了GitHub上，编译和运行这个例子的方法我也写在了项目的README中，你可以点击<a target="_blank" rel="noopener noreferrer" href="https://github.com/liyue2008/kafka-flink-exactlyonce-example">这里<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>查看。</p><h2 id="小结"><a aria-hidden="true" tabindex="-1" href="/blog-two/消息队列进阶/04.案例篇/02#小结"><span class="icon icon-link"></span></a>小结</h2><p>端到端Exactly Once语义，可以保证在分布式系统中，每条数据不多不少只被处理一次。在流计算中，因为数据重复会导致计算结果错误，所以Exactly Once在流计算场景中尤其重要。Kafka和Flink都提供了保证Exactly Once的特性，配合使用可以实现端到端的Exactly Once语义。</p><p>在Flink中，如果节点出现故障，可以自动重启计算任务，重新分配计算节点来保证系统的可用性。配合CheckPoint机制，可以保证重启后任务的状态恢复到最后一次CheckPoint，然后从CheckPoint中记录的恢复位置继续读取数据进行计算。Flink通过一个巧妙的Barrier使CheckPoint中恢复位置和各节点状态完全对应。</p><p>Kafka的Exactly Once语义是通过它的事务和生产幂等两个特性来共同实现的。在配合Flink的时候，每个Flink的CheckPoint对应一个Kafka事务，只要保证CheckPoint和Kafka事务同步提交就可以实现端到端的Exactly Once，Flink通过“二阶段提交”这个分布式事务的经典算法来保证CheckPoint和Kafka事务状态的一致性。</p><p>可以看到，Flink配合Kafka来实现端到端的Exactly Once语义，整个实现过程比较复杂，但是，这个复杂的大问题是由一个一个小问题组成的，每个小问题的原理都是很简单的。比如：Kafka如何实现的生产幂等？Flink如何通过存储计算分离解决子任务状态恢复的？很多这些小问题和我们课程中遇到的类似问题是差不多的，那你就可以用到我们学习过的解决方法。</p><p>你需要重点掌握的是，每一个小问题它面临的场景是什么样的，以及如何解决问题的方法。而不要拘泥于，Kafka或者Flink的某个参数怎么配这些细节问题。这些问题可以等到你在生产中真正需要使用的时候，再去读文档，“现学现卖”都来得及。</p><h2 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-two/消息队列进阶/04.案例篇/02#思考题"><span class="icon icon-link"></span></a>思考题</h2><p>我们的课程中反复强调过，在消息队列的消费端，一定要“先执行消费业务逻辑，再确认消费”，这样才能保证不丢数据。我们这节课中，并没有提到FlinkKafkaConsumer在从数据源主题ip_count_sink消费数据之后，如何来确认消费的。如果消费位置管理不好，一样会导致消息丢失或者重复，课后请你查看一下相关的文档和源代码，看一下FlinkKafkaConsumer是如何来确认消费的。欢迎在留言区与我分享讨论。</p><p>感谢阅读，如果你觉得这篇文章对你有一些启发，也欢迎把它分享给你的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/docs/消息队列进阶/04.案例篇/02.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">5/2/2022 02:41:12</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-two/umi.js"></script>
  </body>
</html>
