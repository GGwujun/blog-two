<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-two/umi.css" />
    <script>
      window.routerBase = "/blog-two";
    </script>
    <script>
      //! umi version: 3.5.17
    </script>
    <script>
      !(function () {
        var e = localStorage.getItem("dumi:prefers-color"),
          t = window.matchMedia("(prefers-color-scheme: dark)").matches,
          r = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === r[2] ? (t ? r[1] : r[0]) : r.indexOf(e) > -1 ? e : r[0]
        );
      })();
    </script>
    <title>03 | 如何实现一个性能优异的Hash表？</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/redis源码剖析与实战/02.数据结构模块/02" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-two/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-two/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-two/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-two/零基础学python">零基础学python</a></li><li><a href="/blog-two/redis核心技术与实战">redis核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-two/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-two/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-two/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-two/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li></ul></span><span>架构师<ul><li><a href="/blog-two/持续交付36讲">持续交付36讲</a></li><li><a href="/blog-two/容器实战高手课">容器实战高手课</a></li><li><a href="/blog-two/ddd实战课">ddd实战课</a></li><li><a href="/blog-two/设计模式之美">设计模式之美</a></li><li><a href="/blog-two/devops实战笔记">devops实战笔记</a></li><li><a href="/blog-two/架构实战案例解析">架构实战案例解析</a></li><li><a href="/blog-two/许式伟的架构课">许式伟的架构课</a></li><li><a href="/blog-two/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-two/深入剖析kubernetes">深入剖析kubernetes</a></li><li><a href="/blog-two/说透中台">说透中台</a></li><li><a href="/blog-two/消息队列进阶">消息队列进阶</a></li><li><a href="/blog-two/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-two/openresty从入门到实战">openresty从入门到实战</a></li><li><a href="/blog-two/赵成的运维体系管理课">赵成的运维体系管理课</a></li><li><a href="/blog-two/性能测试实战30讲">性能测试实战30讲</a></li><li><a href="/blog-two/安全攻防技能30讲">安全攻防技能30讲</a></li><li><a href="/blog-two/从0开始学架构">从0开始学架构</a></li><li><a href="/blog-two/vim实用技巧必知必会">vim实用技巧必知必会</a></li><li><a href="/blog-two/如何落地业务建模">如何落地业务建模</a></li><li><a href="/blog-two/技术与商业案例解读">技术与商业案例解读</a></li><li><a href="/blog-two/说透数字化转型">说透数字化转型</a></li><li><a href="/blog-two/遗留系统现代化实战">遗留系统现代化实战</a></li></ul></span><span>管理<ul><li><a href="/blog-two/技术管理实战36讲">技术管理实战36讲</a></li><li><a href="/blog-two/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-two/项目管理实战课">项目管理实战课</a></li><li><a href="/blog-two/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-two/技术领导力实战笔记">技术领导力实战笔记</a></li><li><a href="/blog-two/朱赟的技术管理">朱赟的技术管理</a></li></ul></span><span>工作生活<ul><li><a href="/blog-two/10x程序员工作法">10x程序员工作法</a></li><li><a href="/blog-two/python自动化办公实战课">python自动化办公实战课</a></li><li><a href="/blog-two/人人都用得上的写作课">人人都用得上的写作课</a></li><li><a href="/blog-two/体验设计案例课">体验设计案例课</a></li><li><a href="/blog-two/用户体验设计实战课">用户体验设计实战课</a></li><li><a href="/blog-two/程序员的个人财富课">程序员的个人财富课</a></li><li><a href="/blog-two/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-two/职场求生攻略">职场求生攻略</a></li><li><a href="/blog-two/讲好故事">讲好故事</a></li><li><a href="/blog-two/跟着高手学复盘">跟着高手学复盘</a></li></ul></span><span>杂谈</span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-two/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-two/go语言核心36讲">go语言核心36讲</a></li><li><a href="/blog-two/go并发编程实战">go并发编程实战</a></li><li><a href="/blog-two/零基础学python">零基础学python</a></li><li><a href="/blog-two/redis核心技术与实战">redis核心技术与实战</a></li><li><a aria-current="page" class="active" href="/blog-two/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-two/陈天rust编程第一课">陈天rust编程第一课</a></li><li><a href="/blog-two/tonybaigo语言第一课">tonybaigo语言第一课</a></li><li><a href="/blog-two/深入c语言和程序运行原理">深入c语言和程序运行原理</a></li></ul></li><li>架构师<ul><li><a href="/blog-two/持续交付36讲">持续交付36讲</a></li><li><a href="/blog-two/容器实战高手课">容器实战高手课</a></li><li><a href="/blog-two/ddd实战课">ddd实战课</a></li><li><a href="/blog-two/设计模式之美">设计模式之美</a></li><li><a href="/blog-two/devops实战笔记">devops实战笔记</a></li><li><a href="/blog-two/架构实战案例解析">架构实战案例解析</a></li><li><a href="/blog-two/许式伟的架构课">许式伟的架构课</a></li><li><a href="/blog-two/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-two/深入剖析kubernetes">深入剖析kubernetes</a></li><li><a href="/blog-two/说透中台">说透中台</a></li><li><a href="/blog-two/消息队列进阶">消息队列进阶</a></li><li><a href="/blog-two/mysql实战45讲">mysql实战45讲</a></li><li><a href="/blog-two/openresty从入门到实战">openresty从入门到实战</a></li><li><a href="/blog-two/赵成的运维体系管理课">赵成的运维体系管理课</a></li><li><a href="/blog-two/性能测试实战30讲">性能测试实战30讲</a></li><li><a href="/blog-two/安全攻防技能30讲">安全攻防技能30讲</a></li><li><a href="/blog-two/从0开始学架构">从0开始学架构</a></li><li><a href="/blog-two/vim实用技巧必知必会">vim实用技巧必知必会</a></li><li><a href="/blog-two/如何落地业务建模">如何落地业务建模</a></li><li><a href="/blog-two/技术与商业案例解读">技术与商业案例解读</a></li><li><a href="/blog-two/说透数字化转型">说透数字化转型</a></li><li><a href="/blog-two/遗留系统现代化实战">遗留系统现代化实战</a></li></ul></li><li>管理<ul><li><a href="/blog-two/技术管理实战36讲">技术管理实战36讲</a></li><li><a href="/blog-two/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-two/项目管理实战课">项目管理实战课</a></li><li><a href="/blog-two/技术面试官识人手册">技术面试官识人手册</a></li><li><a href="/blog-two/技术领导力实战笔记">技术领导力实战笔记</a></li><li><a href="/blog-two/朱赟的技术管理">朱赟的技术管理</a></li></ul></li><li>工作生活<ul><li><a href="/blog-two/10x程序员工作法">10x程序员工作法</a></li><li><a href="/blog-two/python自动化办公实战课">python自动化办公实战课</a></li><li><a href="/blog-two/人人都用得上的写作课">人人都用得上的写作课</a></li><li><a href="/blog-two/体验设计案例课">体验设计案例课</a></li><li><a href="/blog-two/用户体验设计实战课">用户体验设计实战课</a></li><li><a href="/blog-two/程序员的个人财富课">程序员的个人财富课</a></li><li><a href="/blog-two/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-two/职场求生攻略">职场求生攻略</a></li><li><a href="/blog-two/讲好故事">讲好故事</a></li><li><a href="/blog-two/跟着高手学复盘">跟着高手学复盘</a></li></ul></li><li>杂谈</li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-two/redis源码剖析与实战">redis源码剖析与实战</a></li><li><a href="/blog-two/redis源码剖析与实战/01.课前导读">01.课前导读</a><ul><li><a href="/blog-two/redis源码剖析与实战/01.课前导读/01"><span>开篇词 | 阅读Redis源码能给你带来什么？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/01.课前导读/02"><span>01 | 带你快速攻略Redis源码的整体架构</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-two/redis源码剖析与实战/02.数据结构模块">02.数据结构模块</a><ul><li><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/01"><span>02 | 键值对中字符串的实现，用char*还是结构体？</span></a></li><li><a aria-current="page" class="active" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02"><span>03 | 如何实现一个性能优异的Hash表？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/03"><span>04 | 内存友好的数据结构该如何细化设计？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/04"><span>05 | 有序集合为何能同时支持点查询和范围查询？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/05"><span>06 | 从ziplist到quicklist，再到listpack的启发</span></a></li><li><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/06"><span>07 | 为什么Stream使用了Radix Tree？</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/03.事件驱动框架和执行模型模块">03.事件驱动框架和执行模型模块</a><ul><li><a href="/blog-two/redis源码剖析与实战/03.事件驱动框架和执行模型模块/01"><span>08 | Redis server启动后会做哪些操作？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/03.事件驱动框架和执行模型模块/02"><span>09 | Redis事件驱动框架（上）：何时使用select、poll、epoll？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/03.事件驱动框架和执行模型模块/03"><span>10 | Redis事件驱动框架（中）：Redis实现了Reactor模型吗？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/03.事件驱动框架和执行模型模块/04"><span>11 | Redis事件驱动框架（下）：Redis有哪些事件？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/03.事件驱动框架和执行模型模块/05"><span>12 | Redis真的是单线程吗？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/03.事件驱动框架和执行模型模块/06"><span>13 | Redis 6.0多IO线程的效率提高了吗？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/03.事件驱动框架和执行模型模块/07"><span>14 | 从代码实现看分布式锁的原子性保证</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/04.缓存模块">04.缓存模块</a><ul><li><a href="/blog-two/redis源码剖析与实战/04.缓存模块/01"><span>15 | 为什么LRU算法原理和代码实现不一样？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/04.缓存模块/02"><span>16 | LFU算法和其他算法相比有优势吗？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/04.缓存模块/03"><span>17 | Lazy Free会影响缓存替换吗？</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/05.期中测试">05.期中测试</a><ul><li><a href="/blog-two/redis源码剖析与实战/05.期中测试/01"><span>期中测试 | 这些Redis源码知识，你都掌握了吗？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/05.期中测试/02"><span>期中测试题答案 | 这些问题你都答对了吗？</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块">06.可靠性保证模块</a><ul><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块/01"><span>18 | 如何生成和解读RDB文件？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块/02"><span>19 | AOF重写（上）：触发时机与重写的影响</span></a></li><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块/03"><span>20 | AOF重写（下）：重写时的新写操作记录在哪里？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块/04"><span>21 | 主从复制：基于状态机的设计与实现</span></a></li><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块/05"><span>22 | 哨兵也和Redis实例一样初始化吗？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块/06"><span>23 | 从哨兵Leader选举学习Raft协议实现（上）</span></a></li><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块/07"><span>24 | 从哨兵Leader选举学习Raft协议实现（下）</span></a></li><li><a href="/blog-two/redis源码剖析与实战/06.可靠性保证模块/08"><span>25 | Pub/Sub在主从故障切换时是如何发挥作用的？</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/07.不定期加餐">07.不定期加餐</a><ul><li><a href="/blog-two/redis源码剖析与实战/07.不定期加餐/01"><span>加餐1 | Redis性能测试工具的使用</span></a></li><li><a href="/blog-two/redis源码剖析与实战/07.不定期加餐/02"><span>加餐2 | 用户Kaito：我是怎么读Redis源码的？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/07.不定期加餐/03"><span>加餐3 | 从Redis到其他键值数据库的学习体会</span></a></li><li><a href="/blog-two/redis源码剖析与实战/07.不定期加餐/04"><span>加餐4 | RDB和AOF文件损坏了咋办？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/07.不定期加餐/05"><span>用户故事 | 曾轼麟：世上无难事，只怕有心人</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/08.redis-cluster模块">08.RedisCluster模块</a><ul><li><a href="/blog-two/redis源码剖析与实战/08.redis-cluster模块/01"><span>26 | 从Ping-Pong消息学习Gossip协议的实现</span></a></li><li><a href="/blog-two/redis源码剖析与实战/08.redis-cluster模块/02"><span>27 | 从MOVED、ASK看集群节点如何处理命令？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/08.redis-cluster模块/03"><span>28 | Redis Cluster数据迁移会阻塞吗？</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/09.编程技巧模块">09.编程技巧模块</a><ul><li><a href="/blog-two/redis源码剖析与实战/09.编程技巧模块/01"><span>29 | 如何正确实现循环缓冲区？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/09.编程技巧模块/02"><span>30 | 如何在系统中实现延迟监控？</span></a></li><li><a href="/blog-two/redis源码剖析与实战/09.编程技巧模块/03"><span>31 | 从Module的实现学习动态扩展功能</span></a></li><li><a href="/blog-two/redis源码剖析与实战/09.编程技巧模块/04"><span>32 | 如何在一个系统中实现单元测试？</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/10.问题答疑">10.问题答疑</a><ul><li><a href="/blog-two/redis源码剖析与实战/10.问题答疑/01"><span>答疑1 | 第1~6讲课后思考题答案及常见问题答疑</span></a></li><li><a href="/blog-two/redis源码剖析与实战/10.问题答疑/02"><span>答疑2 | 第7~12讲课后思考题答案及常见问题答疑</span></a></li><li><a href="/blog-two/redis源码剖析与实战/10.问题答疑/03"><span>答疑3 | 第13~18讲课后思考题答案及常见问题答疑</span></a></li><li><a href="/blog-two/redis源码剖析与实战/10.问题答疑/04"><span>答疑4 | 第19~24讲课后思考题答案及常见问题答疑</span></a></li><li><a href="/blog-two/redis源码剖析与实战/10.问题答疑/05"><span>答疑5 | 第25~32讲课后思考题答案及常见问题答疑</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/11.结束语">11.结束语</a><ul><li><a href="/blog-two/redis源码剖析与实战/11.结束语/01"><span>结束语 | Redis源码阅读，让我们从新开始</span></a></li><li><a href="/blog-two/redis源码剖析与实战/11.结束语/02"><span>结课测试 | 一套习题，测测你的Redis源码知识掌握程度</span></a></li></ul></li><li><a href="/blog-two/redis源码剖析与实战/summary">redis源码剖析与实战</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="Redis如何实现链式哈希？" data-depth="2"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#redis如何实现链式哈希"><span>Redis如何实现链式哈希？</span></a></li><li title="什么是哈希冲突？" data-depth="3"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#什么是哈希冲突"><span>什么是哈希冲突？</span></a></li><li title="链式哈希如何设计与实现？" data-depth="3"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#链式哈希如何设计与实现"><span>链式哈希如何设计与实现？</span></a></li><li title="Redis如何实现rehash？" data-depth="2"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#redis如何实现rehash"><span>Redis如何实现rehash？</span></a></li><li title="什么时候触发rehash？" data-depth="3"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#什么时候触发rehash"><span>什么时候触发rehash？</span></a></li><li title="rehash扩容扩多大？" data-depth="3"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#rehash扩容扩多大"><span>rehash扩容扩多大？</span></a></li><li title="渐进式rehash如何实现？" data-depth="3"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#渐进式rehash如何实现"><span>渐进式rehash如何实现？</span></a></li><li title="小结" data-depth="2"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#小结"><span>小结</span></a></li><li title="每课一问" data-depth="2"><a href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#每课一问"><span>每课一问</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="03--如何实现一个性能优异的hash表"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#03--如何实现一个性能优异的hash表"><span class="icon icon-link"></span></a>03 | 如何实现一个性能优异的Hash表？</h1><p>你好，我是蒋德钧。今天，我们来聊聊Redis中的Hash。</p><p>我们知道，Hash表是一种非常关键的数据结构，在计算机系统中发挥着重要作用。比如在Memcached中，Hash表被用来索引数据；在数据库系统中，Hash表被用来辅助SQL查询。而对于Redis键值数据库来说，Hash表既是键值对中的一种值类型，同时，Redis也使用一个全局Hash表来保存所有的键值对，从而既满足应用存取Hash结构数据需求，又能提供快速查询功能。</p><p>那么，Hash表应用如此广泛的一个重要原因，就是从理论上来说，它能以O(1)的复杂度快速查询数据。Hash表通过Hash函数的计算，就能定位数据在表中的位置，紧接着可以对数据进行操作，这就使得数据操作非常快速。</p><p>Hash表这个结构也并不难理解，但是在实际应用Hash表时，当数据量不断增加，它的性能就经常会受到<strong>哈希冲突</strong>和<strong>rehash开销</strong>的影响。而这两个问题的核心，其实都来自于Hash表要保存的数据量，超过了当前Hash表能容纳的数据量。</p><p>那么要如何应对这两个问题呢？事实上，这也是在大厂面试中，面试官经常会考核的问题。所以你现在可以先想想，如果你在面试中遇到了这两个问题，你会怎么回答呢？</p><p>OK，思考先到这里，现在我来告诉你Redis是怎么很好地解决这两个问题的。</p><p>Redis为我们提供了一个经典的Hash表实现方案。针对哈希冲突，Redis采用了<strong>链式哈希</strong>，在不扩容哈希表的前提下，将具有相同哈希值的数据链接起来，以便这些数据在表中仍然可以被查询到；对于rehash开销，Redis实现了<strong>渐进式rehash设计</strong>，进而缓解了rehash操作带来的额外开销对系统的性能影响。</p><p>所以这节课，我就带你来学习Redis中针对Hash表的设计思路和实现方法，帮助你掌握应对哈希冲突和优化rehash操作性能的能力，并以此支撑你在实际使用Hash表保存大量数据的场景中，可以实现高性能的Hash表。</p><p>好了，接下来，我们就先来聊聊链式哈希的设计与实现。</p><h2 id="redis如何实现链式哈希"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#redis如何实现链式哈希"><span class="icon icon-link"></span></a>Redis如何实现链式哈希？</h2><p>不过，在开始学习链式哈希的设计实现之前，我们还需要明白Redis中Hash表的结构设计是啥样的，以及为何会在数据量增加时产生哈希冲突，这样也更容易帮助我们理解链式哈希应对哈希冲突的解决思路。</p><h3 id="什么是哈希冲突"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#什么是哈希冲突"><span class="icon icon-link"></span></a>什么是哈希冲突？</h3><p>实际上，一个最简单的Hash表就是一个数组，数组里的每个元素是一个哈希桶（也叫做Bucket），第一个数组元素被编为哈希桶0，以此类推。当一个键值对的键经过Hash函数计算后，再对数组元素个数取模，就能得到该键值对对应的数组元素位置，也就是第几个哈希桶。</p><p>如下图所示，key1经过哈希计算和哈希值取模后，就对应哈希桶1，类似的，key3和key16分别对应哈希桶7和桶4。</p><p><img src="https://static001.geekbang.org/resource/image/08/2f/08ac157a8fbf4d22f8a5217bfea79a2f.jpg?wh=2000x1029" alt=""/></p><p>从图上我们还可以看到，需要写入Hash表的键空间一共有16个键，而Hash表的空间大小只有8个元素，这样就会导致有些键会对应到相同的哈希桶中。</p><p>我们在实际应用Hash表时，其实一般很难预估要保存的数据量，如果我们一开始就创建一个非常大的哈希表，当数据量较小时，就会造成空间浪费。所以，我们通常会给哈希表设定一个初始大小，而当数据量增加时，键空间的大小就会大于Hash表空间大小了。</p><p>也正是由于键空间会大于Hash表空间，这就导致在用Hash函数把键映射到Hash表空间时，不可避免地会出现不同的键被映射到数组的同一个位置上。而如果同一个位置只能保存一个键值对，就会导致Hash表保存的数据非常有限，这就是我们常说的<strong>哈希冲突</strong>。</p><p>比如下图中，key3和key100都被映射到了Hash表的桶5中，这样，当桶5只能保存一个key时，key3和key100就会有一个key无法保存到哈希表中了。</p><p><img src="https://static001.geekbang.org/resource/image/04/d8/04322775d11cea97049bcd4dd8109bd8.jpg?wh=2000x889" alt=""/></p><p>那么我们该如何解决哈希冲突呢？可以考虑使用以下两种解决方案：</p><ul><li>第一种方案，就是我接下来要给你介绍的<strong>链式哈希</strong>。这里你需要先知道，链式哈希的链不能太长，否则会降低Hash表性能。</li><li>第二种方案，就是当链式哈希的链长达到一定长度时，我们可以使用<strong>rehash</strong>。不过，执行rehash本身开销比较大，所以就需要采用我稍后会给你介绍的渐进式rehash设计。</li></ul><p>这里，我们先来了解链式哈希的设计和实现。</p><h3 id="链式哈希如何设计与实现"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#链式哈希如何设计与实现"><span class="icon icon-link"></span></a>链式哈希如何设计与实现？</h3><p>所谓的链式哈希，就是<strong>用一个链表把映射到Hash表同一桶中的键给连接起来</strong>。下面我们就来看看Redis是如何实现链式哈希的，以及为何链式哈希能够帮助解决哈希冲突。</p><p>首先，我们需要了解Redis源码中对Hash表的实现。Redis中和Hash表实现相关的文件主要是<strong>dict.h</strong>和<strong>dict.c</strong>。其中，dict.h文件定义了Hash表的结构、哈希项，以及Hash表的各种操作函数，而dict.c文件包含了Hash表各种操作的具体实现代码。</p><p>在dict.h文件中，Hash表被定义为一个二维数组（dictEntry **table），这个数组的每个元素是一个指向哈希项（dictEntry）的指针。下面的代码展示的就是在dict.h文件中对Hash表的定义，你可以看下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">typedef struct dictht {</span></div><div class="token-line"><span class="token plain">        dictEntry **table; //二维数组</span></div><div class="token-line"><span class="token plain">        unsigned long size; //Hash表大小</span></div><div class="token-line"><span class="token plain">        unsigned long sizemask;</span></div><div class="token-line"><span class="token plain">        unsigned long used;</span></div><div class="token-line"><span class="token plain">    } dictht;</span></div></pre></div><p>那么为了实现链式哈希， Redis在每个dictEntry的结构设计中，<strong>除了包含指向键和值的指针，还包含了指向下一个哈希项的指针</strong>。如下面的代码所示，dictEntry结构体中包含了指向另一个dictEntry结构的<strong>指针*next</strong>，这就是用来实现链式哈希的：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">typedef struct dictEntry {</span></div><div class="token-line"><span class="token plain">        void *key;</span></div><div class="token-line"><span class="token plain">        union {</span></div><div class="token-line"><span class="token plain">            void *val;</span></div><div class="token-line"><span class="token plain">            uint64_t u64;</span></div><div class="token-line"><span class="token plain">            int64_t s64;</span></div><div class="token-line"><span class="token plain">            double d;</span></div><div class="token-line"><span class="token plain">        } v;</span></div><div class="token-line"><span class="token plain">        struct dictEntry *next;</span></div><div class="token-line"><span class="token plain">    } dictEntry;</span></div></pre></div><p>除了用于实现链式哈希的指针外，这里还有一个值得注意的地方，就是在dictEntry结构体中，键值对的值是由一个<strong>联合体v</strong>定义的。这个联合体v中包含了指向实际值的指针*val，还包含了无符号的64位整数、有符号的64位整数，以及double类的值。</p><p>我之所以要提醒你注意这里，其实是为了说明，<strong>这种实现方法是一种节省内存的开发小技巧</strong>，非常值得学习。因为当值为整数或双精度浮点数时，由于其本身就是64位，就可以不用指针指向了，而是可以直接存在键值对的结构体中，这样就避免了再用一个指针，从而节省了内存空间。</p><p>好了，那么到这里，你应该就了解了Redis中链式哈希的实现，不过现在你可能还是不太明白，为什么这种链式哈希可以帮助解决哈希冲突呢？</p><p>别着急，我就拿刚才的例子来说明一下，key3和key100都被映射到了Hash表的桶5中。而当使用了链式哈希，桶5就不会只保存key3或key100，而是会用一个链表把key3和key100连接起来，如下图所示。当有更多的key被映射到桶5时，这些key都可以用链表串接起来，以应对哈希冲突。</p><p><img src="https://static001.geekbang.org/resource/image/28/85/281919546bb9cf97cd70718072389585.jpg?wh=2000x866" alt=""/></p><p>这样，当我们要查询key100时，可以先通过哈希函数计算，得到key100的哈希值被映射到了桶5中。然后，我们再逐一比较桶5中串接的key，直到查找到key100。如此一来，我们就能在链式哈希中找到所查的哈希项了。</p><p>不过，链式哈希也存在局限性，那就是随着链表长度的增加，Hash表在一个位置上查询哈希项的耗时就会增加，从而增加了Hash表的整体查询时间，这样也会导致Hash表的性能下降。</p><p>那么，有没有什么其他的方法可以减少对Hash表性能的影响呢？当然是有的，这就是接下来我要给你介绍的rehash的设计与实现了。</p><h2 id="redis如何实现rehash"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#redis如何实现rehash"><span class="icon icon-link"></span></a>Redis如何实现rehash？</h2><p>rehash操作，其实就是指扩大Hash表空间。而Redis实现rehash的基本思路是这样的：</p><ul><li>首先，Redis准备了两个哈希表，用于rehash时交替保存数据。</li></ul><p>我在前面给你介绍过，Redis在dict.h文件中使用dictht结构体定义了Hash表。不过，在实际使用Hash表时，Redis又在dict.h文件中，定义了一个dict结构体。这个结构体中有一个数组（ht[2]），包含了两个Hash表ht[0]和ht[1]。dict结构体的代码定义如下所示：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">typedef struct dict {</span></div><div class="token-line"><span class="token plain">        …</span></div><div class="token-line"><span class="token plain">        dictht ht[2]; //两个Hash表，交替使用，用于rehash操作</span></div><div class="token-line"><span class="token plain">        long rehashidx; //Hash表是否在进行rehash的标识，-1表示没有进行rehash</span></div><div class="token-line"><span class="token plain">        …</span></div><div class="token-line"><span class="token plain">    } dict;</span></div></pre></div><ul><li>其次，在正常服务请求阶段，所有的键值对写入哈希表ht[0]。</li><li>接着，当进行rehash时，键值对被迁移到哈希表ht[1]中。</li><li>最后，当迁移完成后，ht[0]的空间会被释放，并把ht[1]的地址赋值给ht[0]，ht[1]的表大小设置为0。这样一来，又回到了正常服务请求的阶段，ht[0]接收和服务请求，ht[1]作为下一次rehash时的迁移表。</li></ul><p>这里我画了一张图，以便于你理解ht[0]和ht[1]交替使用的过程。</p><p><img src="https://static001.geekbang.org/resource/image/1b/7f/1bc5b729yy127de43e0548ce0b6e6c7f.jpg?wh=2000x1125" alt=""/></p><p>好，那么在了解了Redis交替使用两个Hash表实现rehash的基本思路后，我们还需要明确的是：在实现rehash时，都需要解决哪些问题？我认为主要有以下三点：</p><ul><li>什么时候触发rehash？</li><li>rehash扩容扩多大？</li><li>rehash如何执行？</li></ul><p>所以下面，我就带你来逐一学习Redis对这三个问题的代码实现，通过代码实现，你就能明晰Redis针对这三个问题的设计思想了。</p><h3 id="什么时候触发rehash"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#什么时候触发rehash"><span class="icon icon-link"></span></a>什么时候触发rehash？</h3><p>首先要知道，Redis用来判断是否触发rehash的函数是 <strong>_dictExpandIfNeeded</strong>。所以接下来我们就先看看，_dictExpandIfNeeded函数中进行扩容的触发条件；然后，我们再来了解下_dictExpandIfNeeded又是在哪些函数中被调用的。</p><p>实际上，_dictExpandIfNeeded函数中定义了三个扩容条件。</p><ul><li>条件一：ht[0]的大小为0。</li><li>条件二：ht[0]承载的元素个数已经超过了ht[0]的大小，同时Hash表可以进行扩容。</li><li>条件三：ht[0]承载的元素个数，是ht[0]的大小的dict_force_resize_ratio倍，其中，dict_force_resize_ratio的默认值是5。</li></ul><p>下面的代码就展示了_dictExpandIfNeeded函数对这三个条件的定义，你可以看下。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">//如果Hash表为空，将Hash表扩为初始大小</span></div><div class="token-line"><span class="token plain">    if (d-&gt;ht[0].size == 0) </span></div><div class="token-line"><span class="token plain">       return dictExpand(d, DICT_HT_INITIAL_SIZE);</span></div><div class="token-line"><span class="token plain">     </span></div><div class="token-line"><span class="token plain">    //如果Hash表承载的元素个数超过其当前大小，并且可以进行扩容，或者Hash表承载的元素个数已是当前大小的5倍</span></div><div class="token-line"><span class="token plain">    if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp;(dict_can_resize ||</span></div><div class="token-line"><span class="token plain">                  d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio))</span></div><div class="token-line"><span class="token plain">    {</span></div><div class="token-line"><span class="token plain">        return dictExpand(d, d-&gt;ht[0].used*2);</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>那么，对于条件一来说，此时Hash表是空的，所以Redis就需要将Hash表空间设置为初始大小，而这是初始化的工作，并不属于rehash操作。</p><p>而条件二和三就对应了rehash的场景。因为在这两个条件中，都比较了Hash表当前承载的元素个数（d-&gt;ht[0].used）和Hash表当前设定的大小（d-&gt;ht[0].size），这两个值的比值一般称为<strong>负载因子（load factor）</strong>。也就是说，Redis判断是否进行rehash的条件，就是看load factor是否大于等于1和是否大于5。</p><p>实际上，当load factor大于5时，就表明Hash表已经过载比较严重了，需要立刻进行库扩容。而当load factor大于等于1时，Redis还会再判断dict_can_resize这个变量值，查看当前是否可以进行扩容。</p><p>你可能要问了，这里的dict_can_resize变量值是啥呀？其实，这个变量值是在dictEnableResize和dictDisableResize两个函数中设置的，它们的作用分别是启用和禁止哈希表执行rehash功能，如下所示：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">void dictEnableResize(void) {</span></div><div class="token-line"><span class="token plain">        dict_can_resize = 1;</span></div><div class="token-line"><span class="token plain">    }</span></div><div class="token-line"><span class="token plain">     </span></div><div class="token-line"><span class="token plain">    void dictDisableResize(void) {</span></div><div class="token-line"><span class="token plain">        dict_can_resize = 0;</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>然后，这两个函数又被封装在了updateDictResizePolicy函数中。</p><p>updateDictResizePolicy函数是用来启用或禁用rehash扩容功能的，这个函数调用dictEnableResize函数启用扩容功能的条件是：**当前没有RDB子进程，并且也没有AOF子进程。**这就对应了Redis没有执行RDB快照和没有进行AOF重写的场景。你可以参考下面给出的代码：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">void updateDictResizePolicy(void) {</span></div><div class="token-line"><span class="token plain">        if (server.rdb_child_pid == -1 &amp;&amp; server.aof_child_pid == -1)</span></div><div class="token-line"><span class="token plain">            dictEnableResize();</span></div><div class="token-line"><span class="token plain">        else</span></div><div class="token-line"><span class="token plain">            dictDisableResize();</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>好，到这里我们就了解了_dictExpandIfNeeded对rehash的判断触发条件，那么现在，我们再来看下Redis会在哪些函数中，调用_dictExpandIfNeeded进行判断。</p><p>首先，通过在<a target="_blank" rel="noopener noreferrer" href="https://github.com/redis/redis/blob/5.0/src/dict.c">dict.c<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>文件中查看_dictExpandIfNeeded的被调用关系，我们可以发现，_dictExpandIfNeeded是被_dictKeyIndex函数调用的，而_dictKeyIndex函数又会被dictAddRaw函数调用，然后dictAddRaw会被以下三个函数调用。</p><ul><li>dictAdd：用来往Hash表中添加一个键值对。</li><li>dictRelace：用来往Hash表中添加一个键值对，或者键值对存在时，修改键值对。</li><li>dictAddorFind：直接调用dictAddRaw。</li></ul><p>因此，当我们往Redis中写入新的键值对或是修改键值对时，Redis都会判断下是否需要进行rehash。这里你可以参考下面给出的示意图，其中就展示了_dictExpandIfNeeded被调用的关系。</p><p><img src="https://static001.geekbang.org/resource/image/90/11/90c261fce9dfe604e29239ba283cef11.jpg?wh=2000x969" alt=""/></p><p>好了，简而言之，Redis中触发rehash操作的关键，就是_dictExpandIfNeeded函数和updateDictResizePolicy函数。<strong>_dictExpandIfNeeded函数</strong>会根据Hash表的负载因子以及能否进行rehash的标识，判断是否进行rehash，而<strong>updateDictResizePolicy函数</strong>会根据RDB和AOF的执行情况，启用或禁用rehash。</p><p>接下来，我们继续探讨Redis在实现rehash时，要解决的第二个问题：rehash扩容扩多大？</p><h3 id="rehash扩容扩多大"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#rehash扩容扩多大"><span class="icon icon-link"></span></a>rehash扩容扩多大？</h3><p>在Redis中，rehash对Hash表空间的扩容是通过<strong>调用dictExpand函数</strong>来完成的。dictExpand函数的参数有两个，<strong>一个是要扩容的Hash表，另一个是要扩到的容量</strong>，下面的代码就展示了dictExpand函数的原型定义：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">int dictExpand(dict *d, unsigned long size);</span></div></pre></div><p>那么，对于一个Hash表来说，我们就可以根据前面提到的_dictExpandIfNeeded函数，来判断是否要对其进行扩容。而一旦判断要扩容，Redis在执行rehash操作时，对Hash表扩容的思路也很简单，就是<strong>如果当前表的已用空间大小为size，那么就将表扩容到size*2的大小。</strong></p><p>如下所示，当_dictExpandIfNeeded函数在判断了需要进行rehash后，就调用dictExpand进行扩容。这里你可以看到，rehash的扩容大小是当前ht[0]已使用大小的2倍。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">dictExpand(d, d-&gt;ht[0].used*2);</span></div></pre></div><p>而在dictExpand函数中，具体执行是由_dictNextPower函数完成的，以下代码显示的Hash表扩容的操作，就是从Hash表的初始大小（DICT_HT_INITIAL_SIZE），不停地乘以2，直到达到目标大小。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">static unsigned long _dictNextPower(unsigned long size)</span></div><div class="token-line"><span class="token plain">    {</span></div><div class="token-line"><span class="token plain">        //哈希表的初始大小</span></div><div class="token-line"><span class="token plain">        unsigned long i = DICT_HT_INITIAL_SIZE;</span></div><div class="token-line"><span class="token plain">        //如果要扩容的大小已经超过最大值，则返回最大值加1</span></div><div class="token-line"><span class="token plain">        if (size &gt;= LONG_MAX) return LONG_MAX + 1LU;</span></div><div class="token-line"><span class="token plain">        //扩容大小没有超过最大值</span></div><div class="token-line"><span class="token plain">        while(1) {</span></div><div class="token-line"><span class="token plain">            //如果扩容大小大于等于最大值，就返回截至当前扩到的大小</span></div><div class="token-line"><span class="token plain">            if (i &gt;= size)</span></div><div class="token-line"><span class="token plain">                return i;</span></div><div class="token-line"><span class="token plain">            //每一步扩容都在现有大小基础上乘以2</span></div><div class="token-line"><span class="token plain">            i *= 2;</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>好，下面我们再来看看Redis要解决的第三个问题，即rehash要如何执行？而这个问题，本质上就是Redis要如何实现渐进式rehash设计。</p><h3 id="渐进式rehash如何实现"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#渐进式rehash如何实现"><span class="icon icon-link"></span></a>渐进式rehash如何实现？</h3><p>那么这里，我们要先搞清楚一个问题，就是<strong>为什么要实现渐进式rehash？</strong></p><p>其实这是因为，Hash表在执行rehash时，由于Hash表空间扩大，原本映射到某一位置的键可能会被映射到一个新的位置上，因此，很多键就需要从原来的位置拷贝到新的位置。而在键拷贝时，由于Redis主线程无法执行其他请求，所以键拷贝会阻塞主线程，这样就会产生<strong>rehash开销</strong>。</p><p>而为了降低rehash开销，Redis就提出了渐进式rehash的方法。</p><p>简单来说，渐进式rehash的意思就是Redis并不会一次性把当前Hash表中的所有键，都拷贝到新位置，而是会分批拷贝，每次的键拷贝只拷贝Hash表中一个bucket中的哈希项。这样一来，每次键拷贝的时长有限，对主线程的影响也就有限了。</p><p>**那么，渐进式rehash在代码层面是如何实现的呢？**这里有两个关键函数：dictRehash和_dictRehashStep。</p><p>我们先来看<strong>dictRehash函数</strong>，这个函数实际执行键拷贝，它的输入参数有两个，分别是全局哈希表（即前面提到的dict结构体，包含了ht[0]和ht[1]）和需要进行键拷贝的桶数量（bucket数量）。</p><p>dictRehash函数的整体逻辑包括两部分：</p><ul><li>首先，该函数会执行一个循环，根据要进行键拷贝的bucket数量n，依次完成这些bucket内部所有键的迁移。当然，如果ht[0]哈希表中的数据已经都迁移完成了，键拷贝的循环也会停止执行。</li><li>其次，在完成了n个bucket拷贝后，dictRehash函数的第二部分逻辑，就是判断ht[0]表中数据是否都已迁移完。如果都迁移完了，那么ht[0]的空间会被释放。因为Redis在处理请求时，代码逻辑中都是使用ht[0]，所以当rehash执行完成后，虽然数据都在ht[1]中了，但Redis仍然会把ht[1]赋值给ht[0]，以便其他部分的代码逻辑正常使用。</li><li>而在ht[1]赋值给ht[0]后，它的大小就会被重置为0，等待下一次rehash。与此同时，全局哈希表中的rehashidx变量会被标为-1，表示rehash结束了（这里的rehashidx变量用来表示rehash的进度，稍后我会给你具体解释）。</li></ul><p>我画了下面这张图，展示了dictRehash的主要执行流程，你可以看下。</p><p><img src="https://static001.geekbang.org/resource/image/e5/d1/e54b90dc143ba7e6eae2cda418ce20d1.jpg?wh=2000x1125" alt=""/></p><p>同时，你也可以通过下面代码，来了解dictRehash函数的主要执行逻辑。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">int dictRehash(dict *d, int n) {</span></div><div class="token-line"><span class="token plain">        int empty_visits = n*10;</span></div><div class="token-line"><span class="token plain">        ...</span></div><div class="token-line"><span class="token plain">        //主循环，根据要拷贝的bucket数量n，循环n次后停止或ht[0]中的数据迁移完停止</span></div><div class="token-line"><span class="token plain">        while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {</span></div><div class="token-line"><span class="token plain">           ...</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">        //判断ht[0]的数据是否迁移完成</span></div><div class="token-line"><span class="token plain">        if (d-&gt;ht[0].used == 0) {</span></div><div class="token-line"><span class="token plain">            //ht[0]迁移完后，释放ht[0]内存空间</span></div><div class="token-line"><span class="token plain">            zfree(d-&gt;ht[0].table);</span></div><div class="token-line"><span class="token plain">            //让ht[0]指向ht[1]，以便接受正常的请求</span></div><div class="token-line"><span class="token plain">            d-&gt;ht[0] = d-&gt;ht[1];</span></div><div class="token-line"><span class="token plain">            //重置ht[1]的大小为0</span></div><div class="token-line"><span class="token plain">            _dictReset(&amp;d-&gt;ht[1]);</span></div><div class="token-line"><span class="token plain">            //设置全局哈希表的rehashidx标识为-1，表示rehash结束</span></div><div class="token-line"><span class="token plain">            d-&gt;rehashidx = -1;</span></div><div class="token-line"><span class="token plain">            //返回0，表示ht[0]中所有元素都迁移完</span></div><div class="token-line"><span class="token plain">            return 0;</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">        //返回1，表示ht[0]中仍然有元素没有迁移完</span></div><div class="token-line"><span class="token plain">        return 1;</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>好，在了解了dictRehash函数的主体逻辑后，我们再看下渐进式rehash是如何按照bucket粒度拷贝数据的，这其实就和全局哈希表dict结构中的rehashidx变量相关了。</p><p>rehashidx变量表示的是<strong>当前rehash在对哪个bucket做数据迁移</strong>。比如，当rehashidx等于0时，表示对ht[0]中的第一个bucket进行数据迁移；当rehashidx等于1时，表示对ht[0]中的第二个bucket进行数据迁移，以此类推。</p><p>而dictRehash函数的主循环，首先会判断rehashidx指向的bucket是否为空，如果为空，那就将rehashidx的值加1，检查下一个bucket。</p><p>**那么，有没有可能连续几个bucket都为空呢？**其实是有可能的，在这种情况下，渐进式rehash不会一直递增rehashidx进行检查。这是因为一旦执行了rehash，Redis主线程就无法处理其他请求了。</p><p>所以，渐进式rehash在执行时设置了一个<strong>变量empty_visits</strong>，用来表示已经检查过的空bucket，当检查了一定数量的空bucket后，这一轮的rehash就停止执行，转而继续处理外来请求，避免了对Redis性能的影响。下面的代码显示了这部分逻辑，你可以看下。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {</span></div><div class="token-line"><span class="token plain">        //如果当前要迁移的bucket中没有元素</span></div><div class="token-line"><span class="token plain">        while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) {</span></div><div class="token-line"><span class="token plain">            //</span></div><div class="token-line"><span class="token plain">            d-&gt;rehashidx++;</span></div><div class="token-line"><span class="token plain">            if (--empty_visits == 0) return 1;</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">        ...</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>而如果rehashidx指向的bucket有数据可以迁移，那么Redis就会把这个bucket中的哈希项依次取出来，并根据ht[1]的表空间大小，重新计算哈希项在ht[1]中的bucket位置，然后把这个哈希项赋值到ht[1]对应bucket中。</p><p>这样，每做完一个哈希项的迁移，ht[0]和ht[1]用来表示承载哈希项多少的变量used，就会分别减一和加一。当然，如果当前rehashidx指向的bucket中数据都迁移完了，rehashidx就会递增加1，指向下一个bucket。下面的代码显示了这一迁移过程。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">while(n-- &amp;&amp; d-&gt;ht[0].used != 0) {</span></div><div class="token-line"><span class="token plain">        ...</span></div><div class="token-line"><span class="token plain">        //获得哈希表中哈希项</span></div><div class="token-line"><span class="token plain">        de = d-&gt;ht[0].table[d-&gt;rehashidx];</span></div><div class="token-line"><span class="token plain">        //如果rehashidx指向的bucket不为空</span></div><div class="token-line"><span class="token plain">        while(de) {</span></div><div class="token-line"><span class="token plain">            uint64_t h;</span></div><div class="token-line"><span class="token plain">            //获得同一个bucket中下一个哈希项</span></div><div class="token-line"><span class="token plain">            nextde = de-&gt;next;</span></div><div class="token-line"><span class="token plain">            //根据扩容后的哈希表ht[1]大小，计算当前哈希项在扩容后哈希表中的bucket位置</span></div><div class="token-line"><span class="token plain">            h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask;</span></div><div class="token-line"><span class="token plain">            //将当前哈希项添加到扩容后的哈希表ht[1]中</span></div><div class="token-line"><span class="token plain">            de-&gt;next = d-&gt;ht[1].table[h];</span></div><div class="token-line"><span class="token plain">            d-&gt;ht[1].table[h] = de;</span></div><div class="token-line"><span class="token plain">            //减少当前哈希表的哈希项个数</span></div><div class="token-line"><span class="token plain">            d-&gt;ht[0].used--;</span></div><div class="token-line"><span class="token plain">            //增加扩容后哈希表的哈希项个数</span></div><div class="token-line"><span class="token plain">            d-&gt;ht[1].used++;</span></div><div class="token-line"><span class="token plain">            //指向下一个哈希项</span></div><div class="token-line"><span class="token plain">            de = nextde;</span></div><div class="token-line"><span class="token plain">        }</span></div><div class="token-line"><span class="token plain">        //如果当前bucket中已经没有哈希项了，将该bucket置为NULL</span></div><div class="token-line"><span class="token plain">        d-&gt;ht[0].table[d-&gt;rehashidx] = NULL;</span></div><div class="token-line"><span class="token plain">        //将rehash加1，下一次将迁移下一个bucket中的元素</span></div><div class="token-line"><span class="token plain">        d-&gt;rehashidx++;</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>好了，到这里，我们就已经基本了解了dictRehash函数的全部逻辑。</p><p>现在我们知道，dictRehash函数本身是按照bucket粒度执行哈希项迁移的，它内部执行的bucket迁移个数，主要由传入的循环次数变量n来决定。但凡Redis要进行rehash操作，最终都会调用dictRehash函数。</p><p>接下来，我们来学习和渐进式rehash相关的第二个关键函数 <strong>_dictRehashStep</strong>，这个函数实现了每次只对一个bucket执行rehash。</p><p>从Redis的源码中我们可以看到，一共会有5个函数通过调用_dictRehashStep函数，进而调用dictRehash函数，来执行rehash，它们分别是：dictAddRaw，dictGenericDelete，dictFind，dictGetRandomKey，dictGetSomeKeys。</p><p>其中，dictAddRaw和dictGenericDelete函数，分别对应了往Redis中增加和删除键值对，而后三个函数则对应了在Redis中进行查询操作。下图展示了这些函数间的调用关系：</p><p><img src="https://static001.geekbang.org/resource/image/05/0a/050cdce01b19a8d03834c18d1feab20a.jpg?wh=2000x820" alt=""/></p><p>但你要注意，不管是增删查哪种操作，这5个函数调用的_dictRehashStep函数，给dictRehash传入的循环次数变量n的值都为1，下面的代码就显示了这一传参的情况。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">static void _dictRehashStep(dict *d) {</span></div><div class="token-line"><span class="token plain">    //给dictRehash传入的循环次数参数为1，表明每迁移完一个bucket ，就执行正常操作</span></div><div class="token-line"><span class="token plain">        if (d-&gt;iterators == 0) dictRehash(d,1);</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>这样一来，每次迁移完一个bucket，Hash表就会执行正常的增删查请求操作，这就是在代码层面实现渐进式rehash的方法。</p><h2 id="小结"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#小结"><span class="icon icon-link"></span></a>小结</h2><p>实现一个高性能的Hash表不仅是Redis的需求，也是很多计算机系统开发过程中的重要目标。而要想实现一个性能优异的Hash表，就需要重点解决哈希冲突和rehash开销这两个问题。</p><p>今天这节课，我带你学习了Redis中Hash表的结构设计、链式哈希方法的实现，以及渐进式rehash方法的设计实现。Redis中Hash表的结构设计很特别，它的每个哈希项都包含了一个指针，用于实现链式哈希。同时，Redis在全局哈希表中还包含了两个Hash表，这种设计思路也是为了在实现rehash时，帮助数据从一个表迁移到另一个表。</p><p>此外，Redis实现的渐进式rehash是一个用于Hash表扩容的通用方法，非常值得我们学习。这个设计方法的关键是每次仅迁移有限个数的bucket，避免一次性迁移给所有bucket带来的性能影响。当你掌握了渐进式rehash这个设计思想和实现方法，你就可以把它应用到自己的Hash表实现场景中。</p><h2 id="每课一问"><a aria-hidden="true" tabindex="-1" href="/blog-two/redis源码剖析与实战/02.数据结构模块/02#每课一问"><span class="icon icon-link"></span></a>每课一问</h2><p>Hash函数会影响Hash表的查询效率及哈希冲突情况，那么，你能从Redis的源码中，找到Hash表使用的是哪一种Hash函数吗？</p><p>欢迎在留言区分享你的答案，如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/docs/redis源码剖析与实战/02.数据结构模块/02.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">5/2/2022 02:41:21</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-two/umi.js"></script>
  </body>
</html>
